## 算法的时间复杂度
假设每行代码的执行时间为t，那么

```Java
  int sunFunc(int n){   
    int num = 0;  //执行一次
    
    for (int i = 0; i<n; i++){  //执行n次
      num = num + i;  //执行n次
    }
    
    return num; //执行一次
  }
```

这块代码执行的时间就是 *(2n+2)\*t*，同样

```Java
    int sunFunc(int n){
        int num = 0; //执行一次
        
        for(int i = 0; i<n; i++){   //执行n次
            for(int j = 0; j<n; j++){   //执行n*n次
                num = num + i * j;  //执行n*n次
            }
        }
        
        return num; //执行一次
    }
```

这块代码执行的时间就是*(2n^2+n+2)\*t*。

在数据结构算法中，通常使用T(n)表示代码执行时间，n表示数据规模大小，f(n)表示代码执行次数综合，所以上面的例子可以表示为 ***f(n) = (2n^2+n+2)\*t***。

O表示代码执行时间与f(n)成正比，也就是**代码执行时间T(n)与每行代码的执行次数n成正比**，*T(n)=O(f(n))*。

所以第一个例子中 ***T(n)=O(2n+2)***，第二个例子中 ***T(n)=O(2n^2+n+2)***，这就是时间复杂度表示法，也叫大O时间复杂度表示法。

***但是***，大O的时间复杂度并不是代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以也叫**渐进时间复杂度**。

当n变得越来越大时，公式中的低阶，常量，系数三部分影响不了其增长趋势，所以可以直接忽略他们，只记录一个最大的量级就行，即上面例子的实际时间复杂度为：***T(n)=O(n)***，***T(n)=O(n^2)***

### 时间复杂度的分析与计算方法

#### (1)循环次数最多原则
```Java
  int sunFunc(int n){
    int sum = 0; //执行一次，忽略不计
    
    for(int =0;i<n;i++>){
      sum += i; //循环内执行次数最多，执行次数为n次，因此时间复杂度记为O(n)
    }
    
    return sum; //执行一次，忽略不计
  }
```
#### （2）加法原则
```Java
  int sunFunc(int n){
    int sum = 0;  //常量级，忽略
    
    for(int i = 0; i < 99; i++){
      sum += i; //执行一百次，还是常量级，忽略
    }
    
    for(int i = 0; i < n; i++){
      sum += i; //执行n次
    }
    
    for(int i = 0; i < n; i++){
      for(int j = 0; j <n; j++){
        sum += i;   //执行n^2次
      }
    }
    
    return sum;   //忽略
  }
```

上述例子中，最大两块代码时间复杂度为*O(n)*和*O(n^2)*，其结果本应该是*T(n)=O(n)+O(n^2)*，我们**只取其中最大量级**，因此整段代码的复杂度为：*O(n^2)*


#### （3）乘法原则

    嵌套代码的复杂度等于嵌套内代码复杂度的乘积

```Java
  void Func1(int n){
    for(int i = 0; i < n; i++){
      Func2(n);       //执行n次，每次都会调用Func函数执行n次
    }
  }

  void Func1(int n){
    for(int i = 0; i < n; i++){
      sum += i;     //执行n次
    }
  }
```

因此这段代码时间复杂度为*O(n)\*O(n) = O(n\*n)*，同理，如果把其中一个n换成m，那么它的时间复杂度就是*O(n\*m)*。

### 常见的几种时间复杂度

#### （1）O(1)常量级时间复杂度
```Java
  void Func(){
    int sum = 0
    
    for(int i = 0; i < 100; i++){
      sum += i;   //执行一百次，也是常量级，几位O(1)
    }
  }

  void Func(){
    System.out.print("1");
    System.out.print("2");
    System.out.print("3");
    // 各执行一次，还是记为O(1)
  }
```
可见*O(1)*并不是说代码只有一行，1只代表一个常量，即时它有一万行这样的也是O(1)，因此它**是固定不会变化的（也就是常量）**，所以凡是常量级复杂度代码，都记为O(1)。


#### （2）常见的O(n)时间复杂度
```Java
  void Func(int n){
    for( int i = 0; i < n; i++){
      System.out.print("1");
    }
  }
```

#### （3）O(logn),O(nlogn)
首先回忆下换底公式：
    *loga(b)\*logc(a) = logc(b)*

```Java
  void Func(int n){
    for( int i = 0; i < n; i++){
      i = i*2;
    }
  }
```

可以看出，i=i*2这行代码执行次数是最多的，那么到底执行了多少次呢？第一次i=2，第二次i=4，第三次i=8...

假设它执行了x次，那么x与n的关系就为： 
>    *x = log2(n)*

当上述代码的2改成3时，x的取值也就是：
>    *x = log3(n)*

也就是不管log的底数到底是几，是e也好，是10也罢，统统都记为:
>    *log(n)*

在换底公式中我们可以知道：
>    *log3(n) = log3(2) \* log2(n)*

可以看出其中**log3(2)是一个常数，忽略它！也就说不管底数是多少到最后都会变成2，所以统统记为O(logn)**。

```Java  
  void Func(int n){
    for( int i = 0; i < n; i++){
      Func2()   //执行n次，嵌套调用，每次调用执行logn次
    }
  }
  void Func2(int n){
    for( int i = 0; i < n; i++){
      i = i * 2;  //执行logn次
    }
  }
```

所以在该例子中的时间复杂度就为:*O(n) = O(nlogn)*

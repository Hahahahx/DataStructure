## 位值制计数法
=======================
> 关键名词：数码、基数、位权
* 数码：使用的数字符号
* 基数：每个进制的基数，如十进制就是十、二进制就是二
* 位权：固定位置对应的单位值

* 十进制的数码：0、1、2、3、4、5、6
* 十进制的基数：10
* 十进制的位权：个、十、百、千、万、亿
> ### 2019
    >> 2*1000 + 0*100 + 1*10 + 9*1
    >> 2*10^3 + 0*10*2 + 1*10^1 + 9*10^0
    >> 位权：数码位置所代表的固定单位值 = 基数^n(指数n的规律：从0开始，从右往左，顺序递增)
> ### 0.1256
    >> 1*1/10 + 2*1/100 + 5*1/1000 + 6*1/10000
    >> 1*10^-1 + 2*10^-2 + 5*10^-3 + 6*10^-4

## JDK自带的进制转换
========================
> Java可以直接声明2、8、10、16进制数,前缀不区分大小写

* 二进制    ：int bin = 0b1100010;  以0b为前缀
* 八进制    ：int oct = 0142;       以0为前缀
* 十进制    ：int dec = 98;         默认无前缀
* 十六进制  : int hex = 0x62;       以0x为前缀
    > 虽然允许使用四种进制的数值，但Java底层存储还是以二进制的方式，并且默认使用十进制的方式显示输出。

    ### Integer对象
    * 有自带的进制转换函数，但是Integer对象最多只能处理36进制前的数据
    * 十进制转换其他进制：
        > Integer.toString(98,5);   // 343，5进制处理
        > Integer.toString(98,36);   // 2q，36进制处理
        > Integer.toString(98,37);   // 98，37进制超出运算范围，无法处理，返回默认十进制数
    * 其他进制转换十进制：
        > Integer.parseInt(String s, int radix);    // return int类型
        > Integer.valueOf(String s, int radix);     // return Integer包装类型

## 位运算
========================
> 位运算就是直接对整数在内存中的二进制位进行（逻辑、位移）操作。

* 比特（bit）：信息量的最小单位，1或者0，单位为小写b。
* 字节（byte）：表示信息的最小单位，计算机存储的基本单位，1byte = 8bit，即8位的二进制数，单位为大写字母B。
* 机器数：将数据的首位设为符号位，即八位的二进制数，七位表示数值首位表示正负。
    > 原码、反码、补码
    >> 正数：原码 = 反码 = 补码
    >> 负数：反码 = 原码除符号位逐位取反、补码 = 反码末位+1
    >>> 计算机引入反码补码主要是利于运算，负数补码还原真值时逐位取反末尾加1

### Java中的位运算
> &（按位与）、|（按位或）、^（按位异或）、~（按位取反）、<<（左移）、>>（右移）、>>>（无符号右移）

* &，按位与运算，两数都为真结果才真
    > 14 & 3 = 0000 1110 & 0000 0011 = 0000 0010 = 2
    >> 特点：清零特定位，获取特定位
* |，按位或运算，有真结果位真
    > 14 | 3 = 0000 1110 | 0000 0011 = 0000 1111 = 15
    >> 特点：将指定位置替换位1
* ^，按位异或运算，两数不同结果为真
    > 14 ^ 3 = 0000 1110 ^ 0000 0011 = 0000 1101 = 13
    >> 特点：与自身异或结果为0，与同一个数连续异或两次得到其本身，即14^3^3 = 13^3 = 14,3^14^14 = 13^14 = 3;
* ~，按位取反运算，逐位取反
    > ~14 = ~0000 1110 = 1111 0001（补码） = -15
* <<，左位移运算，左侧舍弃，右侧补0
    > 14 << 1 = 0000 1110 << 1 = 0001 1100 = 28
    >> m << n === m*2^n (前提为最高位不为1)
* \>>，右位移运算，右侧舍弃，左侧正补0，负补1
    > 14 >> 1 = 0000 1110 >> 1 = 0000 0111 = 7 、 14 >> 2 = 0000 1110 >> 2 = 0000 0011 = 3
    > -14 >> 1 = 1111 0010 >> 1 = 1111 1001 = -7 、 -14 >> 2 = 1111 0010 >> 2 = 1111 1100 = -4
    >> m >> n === m/2^n (低位为1时，精度丢失)
* \>>>，无符号右移，右侧舍弃，左侧补零
    > -14 >>> 2 = 1111 0010 >>> 2 = 0011 1100 = 60                              //以一个字节B表示的-14 
    > -14 >>> 2 = 1111 1111 1111 0010 >>> 2 = 0011 1111 1111 1100 = 16380       //以两个字节B表示的16380
    >> 无符号位右移只是在操作时不去考虑其符号位，而在最终结果仍然以补码形式的符号表示，所以占用内存大小不同的两个一样的数经过无符号右移以后得出的结果也可能不同。

## Java中的整数类型
=============================

* byte(1字节)   : -128~+127
* short(2字节)  : -32768~+32767
* int(4字节)    : -2147483648~+2147483647
* long(8字节)   : -9223372036854775808~+9223372036854775807

### 大端模式与小端模式
> 一个字节占一个地址，那么多字节数据要注意其存储方式，字节序与编程语言无关，取决于计算机处理器的设计架构，如Intel x86系列就是小端序，说白了就是一个数据在地址编号中的存放顺序。位权大的称为高位字节，位权小的称为低位字节。

> ！Java中默认使用的是大端模式。

如16进制数（8字节数据）：0x12345678，两位为一个字节。即 [高] 12 - 78 [低]
地址编号：[低] 0x00000001 - 0x00000004 [高]

* 大端（big-endian）    ： 高位字节放在低地址，低位字节放在高地址。
* 小端（little-endian） ： 低位字节放在低地址，高位字节放在高地址。

> 大端序中内存地址存放：
    0x00000001 ： 12    //12为高位字节，存放在低位地址中
    0x00000002 ： 34    //34相对12为低位字节，相对56为高位字节
    0x00000003 ： 56    //56相对34为低位字节，相对78为高位字节
    0x00000004 ： 78    //78为低位字节，存放在高位地址中

> 小端序中内存地址存放：
    0x00000001 ： 78    //78为低位字节，存放在低位地址中
    0x00000002 ： 56    //56相对78为高位字节，相对34为低位字节
    0x00000003 ： 34    //34相对56为高位字节，相对12为低位字节
    0x00000004 ： 12    //12为高位字节，存放在低位地址中

>> 大端序是按照数字的书写顺序进行存储的，而小端序是颠倒书写顺序进行存储的。

### 大数类BigInteger
> 理论无限大[计算机内存可以表示的最大范围]的整数。

#### 创建方法
* BigInteger(String val)            //十进制字符串表示形式转换为BigInteger
* BigInteger(String val,int radix)  //指定基数的字符串表示形式转换为BigInteger
* static valueOf(long val)          //返回其值等于指定long的值的BigInteger

#### 计算方法
> 内部定义很多基本运算方法。


## Java中的浮点类型
===============================
> 小数在计算机中分为的定点数与浮点数。

* 定点数：约定所有数值数据的小数隐含在某一个固定位置上。
* 浮点数：数值数据的小数点位置不固定，浮点数就是采取下面的指数规则进行存储。
* 指数规则：任意实数，都可以由一个定点数*基数的整数次幂得到。（科学计数法）
    > 3.14159 = 0.314159*10^1 = 31.4159*10^-1
    > (2.75)十进制 = 0.275*10^1 = (10.11)二进制 = 1.011*2^1 = 0.1011*2^2 = 101.1*2^-1 = 1011*2^-2

### 尾数与阶码
* 定点数部分：尾数
* 指数部分：阶码
> 在存储时，我们只需要尾数和阶码，以及一个符号位，就可以存储这个小数了
  缺点：尾数和阶码位数不固定。
  解决：电气电子工程师协会提出，二进制浮点算法标准：IEEE754

#### IEEE754二进制浮点标准

* 单精度float(4Byte)
> float ： 1位符号位S + 8位阶码E + 23位尾数M
* 双精度double(8Byte)
> double ： 1位符号位S + 11位阶码E + 52位尾数M

#### IEEE754尾数的定点形式
* 尾数M ： 纯小数形式，小数点在尾数的最前端，通常为\规约形式\。
> 规约形式 ： 在科学表示法下，小数的最高有效位是1（整数部分）
    >> 如十进制 12.5625 = 二进制 1100.1001 = 1.1001001*2^3  
    >>> 那么在存储时我们只存储尾数（.1001001）部分，整数不进行存储默认为1，也就是说如double类型中有52位的尾数，但在实际存储中我们可以存储53位的尾数，因为首位被隐含了，以规定设置为1了。
    >> 纯小数十进制 0.5625 = 二进制 0.1001 = 1.001*2^-1         //此处也一样。尾数部分只存储(.1001)，省略首位1。

#### IEEE754阶码的记录形式
* 阶码 ： 通常使用\移码(增码)\来表示
> 移码 ： 将数值正向偏移（2^e-1），等于符号位取反的补码。        
    >> e取位数的限制，在8位float阶码长度下，表示为 2^(8-1) = 2^7 = 128
    >>> 正向增加128，由于位数限制，移码的实际值就等于补码的符号位取反，为什么要这样做，因为如果不采用这种方式，那么计算机符号位仍然参与运算，那么以1开始的负值恒定大于0起始的正值。
        如 +1 = 补码 0000 0001 = 移码 1000 0001 - 128 = 129 - 128
           -1 = 补码 1111 1111 = 移码 0111 1111 - 128 = 127 - 128

#### 在规定中，阶码使用移码（标准移码-1）记录指数，实际偏移值位（2^(e-1)-1)，即在float八位阶码中的偏移值就变成了127，而在double十一位的阶码中偏移值就是1023。

#### IEEE754的实值计算规则（IEEE754标准中的格式化浮点数真值表示公式）
* float(4字节32位) ： (-1)s * (1+M) * 2^e-(127)
* double(8字节64位)： (-1)s * (1+M) * 2^e-(1023)
> 1|01111110|0100000000000000000000000
> 符号：-  阶码：126-(偏移值127)=-1 尾数：二进制(0.01+(规约形式1)=1.01) = 十进制(1.25) ====>  -(1.25 * 2^-1) = -0.625

#### 非格式化浮点数
* 当阶码E全为1(2^e-1)，且尾数M全为0时：值为无穷大±∞
* 当阶码E全为1(2^e-1)，且尾数M非全0时：代码无效（NaN）
* 当阶码E全为0(0)，且尾数M全为0时：值为±0
* 当阶码E全为0(0)，且尾数M非全0时：由于不存在阶码，其尾数以非规约浮点数形式表示，并且其阶码的偏移值是在之前的基础上再减去1，即
    > 浮点真值：(-1)s * (M) * 2^E(E为-126或者-1022)
    >> 因为使用非规约形式，所以可以表示出比规约形式更小的值，没有了规约形式的固定首位1，其尾数表示范围从1-2，变成了0-1

### 浮点型的精度情况
> 真值F(绝对值) = 尾数M * 2^E(阶码)

* float尾数是23位二进制数，转换成十进制，有效数字6~7位。
* double尾数是52位二进制数，转换成十进制，有效数字15~16位。

> 十进制的小数转化成二进制的小数，大多数都是一种无限循环的情况，所以我们使用二进制存储小数的话，它其实在计算机中存储的只是一个近似值。所以尾数越长，值越精确，而浮点型再通过阶码去计算浮点位置，得到的值就更不精确了。在普通计算中我们只是求出一个近似值问题不大，但是如果在一些商业运算中对结果有十分严格的要求，这时就需要基本类型外的精确小数类BigDecimal。

### 精确小数BigDecimal
> 用来对超过16位有效位的小数进行精确的运算，数值存储使用BigInteger+scale标度进行存储保证精度（其实就是十进科学记数法，BigInteger用来存纯整数，scale用来纯进制指数）。

#### 创建方法
* BigDecimal(String val)            
    > BigDecimal d1 = new BigDecimal("0.1");    //0.1
* BigDecimal(double val)            //不推荐，因为double我们已经知道它存储的是一个近似值，违背了我们使用BigDecimal精确小数的定义。
    > BigDecimal d2 = new BigDecimal(0.2);      //0.200000000000000011102230246251565404236316680908203125
* BigDecimal.valueOf(double val)    //同样使用double，但此时的double使用的是字符串模式进行赋值，所以不会出现无限循环小数的问题。
    > BigDecimal d3 = BigDecimal.valueOf(0.3);  //0.3

#### 计算方法
> 同样无法使用默认的加减乘除，内部定义了这些计算方法供使用。
> 注意：使用divide()方法除法运算时，得到的很有可能会是一个无限循环的小数，而BigDecimal是精确小数，所以如果遇到除不尽的情况是会抛出ArithmeticException的异常。

d1.divide(d3,new MathContext(5, RoundingMode.HALF_UP))  //使用MathContext对其进行环境限制，5位小数，以及四舍五入。

##### RouningMode
> 该参数是BigDecimal是一个枚举类，包含有8个枚举类型，用来说明对经过计算后数值的取舍模式：

* ROUND_UP：远离零方向舍入。向绝对值最大的方向舍入，只要舍弃位非0即进位。
* ROUND_DOWN：趋向零方向舍入。向绝对值最小的方向输入，所有的位都要舍弃，不存在进位情况。
* ROUND_CEILING：向正无穷方向舍入。向正最大方向靠拢。若是正数，舍入行为类似于ROUND_UP，若为负数，舍入行为类似于ROUND_DOWN。Math.round()方法就是使用的此模式。
* ROUND_FLOOR：向负无穷方向舍入。向负无穷方向靠拢。若是正数，舍入行为类似于ROUND_DOWN；若为负数，舍入行为类似于ROUND_UP。
* HALF_UP：最近数字舍入(5进)。这是我们最经典的四舍五入。
* HALF_DOWN：最近数字舍入(5舍)。在这里5是要舍弃的。
* HAIL_EVEN：银行家舍入法。


### boolean占用内存

1、1个bit

理由是boolean类型的值只有true和false两种逻辑值，在编译后会使用1和0来表示，这两个数在内存中只需要1位（bit）即可存储，位是计算机最小的存储单位。

2、1个字节

理由是虽然编译后1和0只需占用1位空间，但计算机处理数据的最小单位是1个字节，1个字节等于8位，实际存储的空间是：用1个字节的最低位存储，其他7位用0填补，如果值是true的话则存储的二进制为：0000 0001，如果是false的话则存储的二进制为：0000 0000。

3、4个字节

理由来源是《Java虚拟机规范》一书中的描述：“虽然定义了boolean这种数据类型，但是只对它提供了非常有限的支持。在Java虚拟机中没有任何供boolean值专用的字节码指令，Java语言表达式所操作的boolean值，在编译之后都使用Java虚拟机中的int数据类型来代替，而boolean数组将会被编码成Java虚拟机的byte数组，每个元素boolean元素占8位”。这样我们可以得出boolean类型占了单独使用是4个字节，在数组中又是1个字节。

显然第三条是更准确的说法，那虚拟机为什么要用int来代替boolean呢？为什么不用byte或short，这样不是更节省内存空间吗。大多数人都会很自然的这样去想，我同样也有这个疑问，经过查阅资料发现，使用int的原因是，对于当下32位的处理器（CPU）来说，一次处理数据是32位（这里不是指的是32/64位系统，而是指CPU硬件层面），具有高效存取的特点。

boolean类型没有给出精确的定义，《Java虚拟机规范》给出了4个字节，和boolean数组1个字节的定义，具体还要看虚拟机实现是否按照规范来，所以1个字节、4个字节都是有可能的。这其实是运算效率和存储空间之间的博弈，两者都非常的重要。







           
